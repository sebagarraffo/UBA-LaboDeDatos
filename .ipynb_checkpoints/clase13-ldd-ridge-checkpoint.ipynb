{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d4b23-8a44-46ac-ba0c-10d33955c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "from sklearn import linear_model    # Herramientas de modelos lineales\n",
    "from sklearn.metrics import mean_squared_error, r2_score    # Medidas de desempeño\n",
    "from sklearn.preprocessing import PolynomialFeatures    # Herramientas de polinomios\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.datasets import make_regression\n",
    "from formulaic import Formula\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a860ad52-6e0b-407c-a279-358e06dd4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si necesitan instalar algún paquete\n",
    "#pip install gapminder\n",
    "#!pip install formulaic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cb394",
   "metadata": {},
   "source": [
    "## Colinealidad y explosión de coeficientes\n",
    "\n",
    "Para cada una de los conjuntos de datos $A$ y $B$, calcular los coeficientes de regresión por mínimos cuadrados al ajustar la variable $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = np.array([[1], [0.001], [0.001]])\n",
    "X_B = np.array([[1, 1.001], [0.001, 0.001], [0.001, 0.001]])\n",
    "y = np.array([1,0,0])\n",
    "display(X_A)\n",
    "display(X_B)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo A\n",
    "modeloA = linear_model.LinearRegression(fit_intercept = False) \n",
    "modeloA.fit(X_A, y)\n",
    "modeloA.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83def2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo B\n",
    "modeloA = linear_model.LinearRegression(fit_intercept = False) \n",
    "modeloA.fit(X_B, y)\n",
    "modeloA.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f648b",
   "metadata": {},
   "source": [
    "# Mínimos cuadrados regularizados\n",
    "\n",
    "Consideramos datos de los precios de viviendas en distintos barrios de Boston. Queremos predecir el precio en función de datos demográficos de cada barrio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datos/BostonHousing.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa9291",
   "metadata": {},
   "source": [
    "## Primero, modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consideramos primero un modelo lineal con todas las variables\n",
    "formula = 'medv ~ crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b'\n",
    "y, X =  Formula(formula).get_model_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d04d0c-b79d-4605-b84a-ea382c3dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f097c-d4dd-4f0a-a4bd-8e0981a085c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eca512-ec65-4d01-91a5-3a14061f1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observación: y es una DataFrame (en realidad, una matriz de formulaic)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7a09b-6ff5-4862-a194-7cefe2081e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos convertirla a serie de Pandas con squeeze().\n",
    "# Es conveniente para graficar o acceder a los valores de la serie\n",
    "y = y.squeeze()\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en testeo y entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo\n",
    "modeloLineal = linear_model.LinearRegression(fit_intercept = False)  # alpha is the hyperparameter equivalent to lambda\n",
    "\n",
    "# Entrenamos\n",
    "modeloLineal.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "y_pred = modeloLineal.predict(X_test)\n",
    "\n",
    "# Evaluamos\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9794c2",
   "metadata": {},
   "source": [
    "Como tenemos datos poblaciones, puede ser útil considerar interacciones (productos entre variables).\n",
    "Por ejemplo tiene sentido multiplicar cantidad de habitantes por salario promedio.\n",
    "\n",
    "Sin pensarlo mucho ni mirar mucho las variables, incorporamos las interacciones entre las variables para ver si podemos mejorar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En Formulaic agregamos interacciones con el simbolo *.\n",
    "# De esta forma se agregan las variables individuales y también los productos.\n",
    "# Más sobre interaccciones en las próximas clases.\n",
    "formula = 'medv ~ (crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b)*(crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b)-1'\n",
    "y, X =  Formula(formula).get_model_matrix(data)\n",
    "y = y.squeeze()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en testeo y entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4771665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "modeloLineal = linear_model.LinearRegression(fit_intercept = True)\n",
    "\n",
    "# Entrenamos\n",
    "modeloLineal.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "y_pred = modeloLineal.predict(X_test)\n",
    "\n",
    "# Evaluamos\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbbe4d",
   "metadata": {},
   "source": [
    "Logramos una reducción importante del error cuadrático.\n",
    "\n",
    "**Ejercicio:** Mirando los coeficientes con cuidado, seleccionar cuáles interacciones son importantes, y utilizar las técnicas vistas de selección de modelos, seleccionar un modelo lineal con pocas variables y similar poder explicativo.\n",
    "\n",
    "Una forma rápida de mirar coeficientes es graficarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2884e-b8c8-48f3-a335-c0474ebdc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(x = np.arange(X.shape[1]))\n",
    "    .add(so.Dot(color = \"r\"), y = modeloLineal.coef_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60424c5-b75b-488d-9fbf-a7b093560c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLineal.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa940b3c",
   "metadata": {},
   "source": [
    "Al introducir tantas variables nuevas, relacionadas con las variables originales, es muy posible que hayamos introducido colinealidad entre las variables.\n",
    "\n",
    "Es razonable entonces intentar un modelo de mínimos cuadrados regularizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9cb947-ae74-4e4c-bdd0-ccbb012916dc",
   "metadata": {},
   "source": [
    "# Regresión Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06a156",
   "metadata": {},
   "source": [
    "**Paso 1:** Separamos los datos en entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45854959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en testeo y entrenamiento\n",
    "df_train, df_test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdd5d7-32f4-463c-a174-8da0b10a6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos las matrices X e y para entrenamiento\n",
    "formula = 'medv ~ (crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b)*(crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b) - 1'\n",
    "y, X =  Formula(formula).get_model_matrix(df_train)\n",
    "y = y.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b40de-1779-4ff0-84b4-592bed9c9a7f",
   "metadata": {},
   "source": [
    "**Pregunta:** Que consideran más apropiado:\n",
    "1. incluir el intecerpt como columna en los datos (y por lo tanto, incluir el coeficiente $\\beta_0$ en la penalización de Ridge)\n",
    "2. excluir el intecerpt como columna en los datos (y por lo tanto, excluir el coeficiente $\\beta_0$ en la penalización de Ridge)\n",
    "\n",
    "<details> <summary>Respuesta (click aquí)</summary>\n",
    "En general debemos excluir el intercept de la penalización. De esta forma nos aseguramos que al tomar valores grandes de $\\alpha$, el modelo se aproxime a la recta constante que mejor aproxima los datos.\n",
    "\n",
    "Si incluimos $\\beta_0$ en la penalidad, al tomar $\\alpha$ grande, nuestro modelos se a aproxima a la recta $y=0$, que no aproxima los datos.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e1177",
   "metadata": {},
   "source": [
    "**Paso 2:** Definimos un vector de parámetros a probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6416a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.array([0.001, 0.01, 0.1, 0.5, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef3088",
   "metadata": {},
   "source": [
    "**Pasos 3 y 4:** Para cada valor de alpha, calculamos el error promedio al realizar validación cruzada de 5 pliegos en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos con un valor de alpha fijo\n",
    "alpha = alphas[0]  # alpha = 0.01\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)  # 5 pliegos\n",
    "\n",
    "modeloRidge = linear_model.Ridge(alpha = alpha, fit_intercept = True)    # Inicializamos un modelo de Regresion Lineal con intercept\n",
    "rmse = np.zeros(cv.get_n_splits())  # Vamos a guardar el error en cada pliego\n",
    "\n",
    "ind = 0\n",
    "\n",
    "# Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "for train_index, val_index in cv.split(X):\n",
    "    X_train, X_val, y_train, y_val = X.iloc[train_index], X.iloc[val_index], y.iloc[train_index], y.iloc[val_index]\n",
    "    modeloRidge.fit(??)\n",
    "    \n",
    "    y_pred = modeloRidge.predict(??)\n",
    "    rmse[ind] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    ind = ind + 1\n",
    "\n",
    "print(f\"Mean Squared Error: {rmse.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c375fe",
   "metadata": {},
   "source": [
    "Esto lo hicimos para un solor valor de alpha, podemos hacerlo fácilmente para varios valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b41260",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "    modeloRidge = linear_model.Ridge(alpha = alpha, fit_intercept = False)    \n",
    "    rmse = np.zeros(cv.get_n_splits())  # Vamos a guardar el error en cada pliego\n",
    "\n",
    "    ind = 0\n",
    "\n",
    "    # Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "    for train_index, val_index in cv.split(X):\n",
    "        X_train, X_val, y_train, y_val = X.iloc[train_index], X.iloc[val_index], y.iloc[train_index], y.iloc[val_index]\n",
    "        modeloRidge.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modeloRidge.predict(X_val)\n",
    "        rmse[ind] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        ind = ind + 1\n",
    "\n",
    "    print(f\"Para alfa = {alpha:.5f} el Error Cuadrático Medio es : {rmse.mean():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49e60a",
   "metadata": {},
   "source": [
    "El valor óptimo es alpha = 0.5.\n",
    "En base a los resultados observados agregamos algunos valores de alpha cercanos a 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75084ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.array([0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 1, 2, 3])\n",
    "error_alphas = np.zeros(len(alphas))\n",
    "\n",
    "for counter, alpha in enumerate(alphas):  # Truco para tener un contador al recorrer una lista\n",
    "    modeloRidge = linear_model.Ridge(alpha = alpha, fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "    rmse = np.zeros(cv.get_n_splits())  # Vamos a guardar el error en cada pliego\n",
    "\n",
    "    ind = 0\n",
    "\n",
    "    # Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "    for train_index, val_index in cv.split(X):\n",
    "        X_train, X_val, y_train, y_val = X.iloc[train_index], X.iloc[val_index], y.iloc[train_index], y.iloc[val_index]\n",
    "        modeloRidge.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modeloRidge.predict(X_val)\n",
    "        rmse[ind] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        ind = ind + 1\n",
    "\n",
    "    print(f\"Para alfa = {alpha:.5f} el Error Cuadrático Medio es : {rmse.mean():.5f}\")\n",
    "    error_alphas[counter] = rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9b0b1",
   "metadata": {},
   "source": [
    "Obtuvimos el valor más chico para $\\alpha = 0.4$. \n",
    "\n",
    "Fijamos este valor y ajustamos el modelo usando todos los datos.\n",
    "\n",
    "**Importante:** \n",
    "1. Los coeficientes de la regresión son **parámetros** y se recalculan utilizando todos los datos.\n",
    "2. El coeficiente $\\alpha$ es un **hiperparámetro**, queda fijo y no se recalcula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_optimo = 0.4\n",
    "\n",
    "modeloRidge = linear_model.Ridge(alpha = alpha_optimo, fit_intercept = True)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modeloRidge.???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de9746",
   "metadata": {},
   "source": [
    "Probamos el modelo obtenido en los datos de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfadbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos las matrices X e y para testeo\n",
    "formula = 'medv ~ (crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b)*(crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat+b)-1'\n",
    "y_test, X_test =  Formula(formula).get_model_matrix(df_test)\n",
    "        \n",
    "y_pred = modeloRidge.???\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"For alpha = {alpha_optimo:.5f} the Root Mean Squared Error is: {rmse.mean():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b938bea",
   "metadata": {},
   "source": [
    "Obtuvimos un error menor!\n",
    "\n",
    "Podemos comparar los coeficientes gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a827e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(x = np.arange(X.shape[1]))\n",
    "    .add(so.Dot(color = \"b\"), y = modeloRidge.coef_)\n",
    "    .add(so.Dot(color = \"r\"), y = modeloLineal.coef_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330d79f-5028-44af-9265-571b8bfc4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLineal.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a71ca-1574-4c11-b6ce-66a785dc893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloRidge.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35959f1f-eba8-4555-9073-53375ffa9d68",
   "metadata": {},
   "source": [
    "Observamos que en los coeficientes del modelo lineal hay valores positivos altos que parecen cancelarse con valores negativos altos. Esto suele indicar colinealidad en las variables. Al hacer regresión Ridge, reducimos los problemas de la colinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515c5cf-4f85-4b30-95c2-f7bca0abe3d9",
   "metadata": {},
   "source": [
    "### Curva de errores \n",
    "Puede ser instructivo graficar el error en función de alfa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d0c8f-2283-4ab8-87a4-96b0cf910a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(x = ???, y = ???)\n",
    "    .add(so.Dot(color = \"b\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d54628-3ff7-4a12-a6ed-908b50e73c66",
   "metadata": {},
   "source": [
    "**Preguntas:**\n",
    "1. Qué pasa si la curva es decreciente?\n",
    "2. Qué pasa si la curva es creciente?\n",
    "3. Qué pasa si alpha = 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d70e35-55b2-4a13-a218-8f08179d7ec8",
   "metadata": {},
   "source": [
    "# Regresión ridge y escalamiento de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac892ee-929e-4486-82c5-7473ed2b8925",
   "metadata": {},
   "source": [
    "Ya vimos que el escalamiento de variables nos puede servir en el modelo lineal para comparar coeficientes del modelo y deducir apropiadamente el peso de cada variable en el modelo.\n",
    "\n",
    "Sin embargo, el escalamiento no afecta la bondad del modelo. El modelo lineal es invariante por escalamientos lineales de variables.\n",
    "\n",
    "¿Qué pasa en regresión Ridge? ¿Será invariante por escalamiento de variables?\n",
    "\n",
    "<details> <summary>Respuesta (click aquí)</summary>\n",
    "Regresión Ridge NO es invariante por escalamiento. Si algunas variable está en una escala muy alta (por ejemplo medida en pesos) comparada con otras variables (por ejemplo medidas en dólares), el resultado será que las variables en dolares sean más penalizadas que las variables en pesos (porque tendrían en general coeficientes mayores).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d2c57-c872-4b5d-8464-7622a579f473",
   "metadata": {},
   "source": [
    "## Caso de estudio: Jugadores de basketball universitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796bcf7-2462-4d5a-8801-329faf42127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball = pd.read_csv(\"../Datos/CollegeBasketballPlayers2009-2021.csv\")\n",
    "basketball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b20482-855c-42aa-b305-04ea44b22a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64a5e5-e8d5-4932-b44e-3964b3a0e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con las variables numéricas\n",
    "basketNumeric = basketball.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd213ef6-3456-47fa-b6d0-79a6083c0f12",
   "metadata": {},
   "source": [
    "### Limpieza de datos: datos faltantes\n",
    "Veamos cuántos datos faltantes hay por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d9029-c566-4deb-bcd3-dc5eeb8b81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None): \n",
    "    print(basketball.isna().sum())  # Cantidad de datos faltantes por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f18a36-eea2-4b18-9d56-dbee95cfff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos primero las columnas con más de 100 datos faltantes\n",
    "nan_cols = basketNumeric.isna().sum() > 100  # Vector booleano\n",
    "keep = nan_cols.index[~(nan_cols)] # Lista con los nombres de las columnas para dejar\n",
    "basketNumeric = basketNumeric[keep] # Seleccionamos solo las columnas en keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ecdbc-eb4e-40b8-bf60-8c04e16b3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos ahora cuantos datos faltantes hay por columna\n",
    "basketNumeric.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696b049-62dc-45c3-b21d-ba68ab3bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora eliminamos todas las filas con datos faltantes\n",
    "basketNumericClean = basketNumeric.dropna()\n",
    "basketNumericClean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cbfb6-8fdd-4599-9b41-3aed7a60132e",
   "metadata": {},
   "source": [
    "Ajutamos primero un modelo lineal sobre todos los datos para predecir la variable pts en función del resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d52819-95ef-4205-b2aa-25460e33d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = basketNumericClean[\"pts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae65a12-f9dc-4539-b0fa-a3ee2f21f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = basketNumericClean.drop([\"pts\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f0cfe-fff9-4e46-93b9-0ccc6593a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "modeloLineal = linear_model.LinearRegression() \n",
    "\n",
    "# Entrenamiento\n",
    "modeloLineal.fit(X, y)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloLineal.predict(X)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b45284-1047-47ee-911a-2f1f3713ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R cuadrado\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d0be0-47fd-4ce3-9e84-7bb6f1f1f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficientes\n",
    "modeloLineal.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60697c-1575-4859-a3b0-1ff0fc7b4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04e332-e5b6-4271-b47d-4806960ee793",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.Plot(x = np.arange(len(modeloLineal.coef_)), y = modeloLineal.coef_).add(so.Dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811f4b9-8697-4d25-bc88-809977e25f9f",
   "metadata": {},
   "source": [
    "Observando los coeficientes, hay coeficientes grandes que se cancelan, indicando posible colinealidad, lo que sugiere utilizar regresión Ridge. \n",
    "\n",
    "Veamos primero si las variables están en la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdec400-bc6f-411f-9722-3373fe7aaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1873d36-daf8-496c-85b6-923798c94bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8627a-94eb-4122-92bd-03740315f5f4",
   "metadata": {},
   "source": [
    "Vemos que hay mucha diferencia en las escalas de las variables. Para poder comparar mejor los coeficientes, escalamos todas la variables al intervalo [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29573f8-fa5d-47d8-89e0-8efbe6ef6907",
   "metadata": {},
   "source": [
    "Utilizamos el escalamiento estándar. Puede utilizarse también MinMax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1ce76-446d-45af-bca7-5270633b644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\") # La última opción hace que nos devuelva un DataFrame\n",
    "\n",
    "# fit_transform calcula los coeficientes de la transformación y la aplica.\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88941cd5-ecc6-4e96-a9f0-77aef2457a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba5865-b00f-450f-8cb1-7e62e1c317e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34619538-32ad-4fc9-abaf-4c0d22e5ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos el modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f138607-350c-461c-bd71-0ee8a815ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "modeloLineal = linear_model.LinearRegression() \n",
    "\n",
    "# Entrenamiento\n",
    "modeloLineal.fit(X_scaled, y)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloLineal.predict(X_scaled)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b709d0b-f9e3-4821-b0d3-c0b8e5096ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "so.Plot(x = np.arange(len(modeloLineal.coef_)), y = modeloLineal.coef_).add(so.Dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cffd59-6d3d-46ef-b996-4f760034f20a",
   "metadata": {},
   "source": [
    "Los problemas de colinealidad son más evidentes ahora.\n",
    "\n",
    "En base a lo observado, vamos a utilizar un modelo de regresión de Ridge.\n",
    "Separamos en entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34468776-8ff3-4b24-81a4-e76fe74ebebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eba89e-cab0-4ef4-a513-4f77f0d0cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "alpha = 1  # Ejercicio: calcular alpha por validacion cruzada\n",
    "modeloRidge = linear_model.Ridge(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf554b46-3193-4d0c-a45f-8d7115f27cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "modeloRidge.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_train)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d99c1-b8d1-49f5-8b80-418fde6cfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los coeficientes\n",
    "so.Plot(x = np.arange(len(modeloRidge.coef_)), y = modeloRidge.coef_).add(so.Dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf45f0-884a-4865-abc2-0cce3006f1c0",
   "metadata": {},
   "source": [
    "Redujimos el problema de coeficientes grandes que se anulan, pero todavía resulta difícil comparar los pesos de las distintas variables. \n",
    "\n",
    "Además en el modelo lineal Ridge penalizamos coeficientes grandes. Si las variables están a distinta escala, esto hace que penalicemos más a algunas variables que a otras.\n",
    "\n",
    "En Regresión Ridge casi siempre es necesario escalar las variables.\n",
    "\n",
    "Reescalamos todas utilizando StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f15d9-1c5f-4fbf-9f25-b2b409f160cc",
   "metadata": {},
   "source": [
    "Al realizar un escalamiento, no incluimos los datos de testeo, porque suponemos que son datos desconocidos para nosotros.\n",
    "StandardScaler nos permite calcular la fórmula de escalamiento en un conjunto de datos y aplicarlo en otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a204e63-3783-4063-b26d-b0a6f94611f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().set_output(transform=\"pandas\") # La última opción hace que nos devuelva un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab2d81-411d-40a0-82dc-23987607d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform calcula los coeficientes de la transformación y la aplica.\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fe4c7-d3ad-4fb3-b76f-5837c574635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "alpha = 1     # Ejercicio: calcular el alpha optimo por validacion cruzada\n",
    "modeloRidge = linear_model.Ridge(alpha = alpha)   \n",
    "\n",
    "# Entrenamiento\n",
    "modeloRidge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_train_scaled)\n",
    "\n",
    "# Evaluación\n",
    "print(\"alpha = \", alpha)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")\n",
    "\n",
    "print(modeloRidge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a76af-5e97-45e4-b16b-e94c06be2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.Plot(x = np.arange(len(modeloRidge.coef_)), y = modeloRidge.coef_).add(so.Dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ad419-1f0a-4e7f-9943-7ab3b55f9478",
   "metadata": {},
   "source": [
    "Ahora queremos ver los resultados en testeo, para eso transformamos los datos de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2719f-f2df-4861-abe6-766f29057446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estará bien hacerlo así?\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4afd26-b324-4526-ae75-2028766d7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_test_scaled)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02e736-4d45-4e2e-b2ba-76aa61433139",
   "metadata": {},
   "source": [
    "No dio muy mal, porque los parámetros del escalamiento son similares (la media y varianza de una muestra es similar a la media varianza de toda la población), pero es incorrecto\n",
    "\n",
    "La forma correcta es fittear en entrenamiento y aplicar esa transformación a los datos de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa1eae-ad46-4198-b910-2f019ee316ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos que fittear en entrenamiento y aplicar esa transformación a los datos de testeo\n",
    "scaler.fit(X_train)   # Primero fiteamos (este paso no es necesario si ya hicimos fit_transform en X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Luego transformamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7c38-774f-4495-acba-6290a8f30316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_test_scaled)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0ec5d-4e14-4b23-9f8d-5a73384f5748",
   "metadata": {},
   "source": [
    "Vemos que mejoraron las predicciones. \n",
    "\n",
    "La diferencia es más notoria si usamos MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e6a56-bc08-4abd-b3bb-a3497c07c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().set_output(transform=\"pandas\") # La última opción hace que nos devuelva un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a2701-2e4c-4ff4-9795-0fb75101ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform calcula los coeficientes de la transformación y la aplica.\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69eaef-50b6-43cd-a264-9cf645a07fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo lineal\n",
    "alpha = 1\n",
    "modeloRidge = linear_model.Ridge(alpha = alpha) \n",
    "\n",
    "# Entrenamiento\n",
    "modeloRidge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_train_scaled)\n",
    "\n",
    "# Evaluación en los datos de entrenamiento\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470d08d-dcd5-4baf-91fd-d808db84a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAL!\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_test_scaled)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebc213-d54b-4345-99f2-f1950f72d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.data_min_, scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cfba7-e276-440a-9bd0-59fb81e363a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIEN\n",
    "\n",
    "# Tenemos que fittear en entrenamiento y aplicar esa transformación a los datos de testeo\n",
    "scaler.fit(X_train)   # Primero fiteamos (este paso no es necesario si ya hicimos fit_transform en X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Luego transformamos\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modeloRidge.predict(X_test_scaled)\n",
    "\n",
    "# Evaluación\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Raíz del Error Cuadrático Medio: {rmse:.5f}\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R cuadrado: {r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9d16d-1b7b-4cd4-a560-03078154606f",
   "metadata": {},
   "source": [
    "## Ejercicio - Repaso\n",
    "Seleccionar el alpha óptimo por validación cruzada en X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f43168-6a65-406b-b5cc-86851d7362ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a1775-8a2a-492e-a497-bbf0798e1535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
